import requests
from bs4 import BeautifulSoup
import re
import json
import pymysql

def fetch_book_info(url):
    headers = {'User-Agent': 'Mozilla/5.0'}
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, 'html.parser')

    # æ›¸å
    title_tag = soup.find('h1')
    title = title_tag.get_text(strip=True) if title_tag else ''

    # æ›¸å°
    cover_tag = soup.select_one('meta[property="og:image"]')
    cover_url = cover_tag['content'] if cover_tag else ''

    # æ›¸ç±ç°¡ä»‹
    description = ''
    desc_div = soup.find('div', class_='content')
    if desc_div:
        lines = [line.strip() for line in desc_div.stripped_strings]
        description = '\n'.join(lines)

    # å¾ meta æŠ“ä½œè€…ã€å‡ºç‰ˆç¤¾èˆ‡é¡åˆ¥
    meta_desc = soup.find('meta', {'name': 'description'})
    meta_content = meta_desc['content'] if meta_desc else ''

    author_match = re.search(r'ä½œè€…ï¼š(.+?)ï¼Œ', meta_content)
    publisher_match = re.search(r'å‡ºç‰ˆç¤¾ï¼š(.+?)ï¼Œ', meta_content)
    category_match = re.search(r'é¡åˆ¥ï¼š(.+?)(?:ï¼Œ|$)', meta_content)

    # å¤šä½œè€…è™•ç†
    authors = []
    if author_match:
        raw_authors = author_match.group(1)
        authors = [a.strip() for a in re.split(r'[ ,ï¼Œ]', raw_authors) if a.strip()]

    publisher = publisher_match.group(1).strip() if publisher_match else ''
    category = category_match.group(1).strip() if category_match else ''

    return {
        'title': title,
        'authors': authors,
        'publisher': publisher,
        'category': category,
        'cover_url': cover_url,
        'description': description
    }

def save_book_to_db(conn, book):
    with conn.cursor() as cursor:
        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
        cursor.execute("SELECT book_id FROM book WHERE title=%s", (book['title'],))
        result = cursor.fetchone()
        if result:
            print(f"âš ï¸ æ›¸ç±ã€Š{book['title']}ã€‹å·²å­˜åœ¨ï¼Œè·³éã€‚")
            return

        # æ’å…¥æ›¸ç±
        sql_book = "INSERT INTO book (title, publisher, category, cover_url, description) VALUES (%s, %s, %s, %s, %s)"
        cursor.execute(sql_book, (book['title'], book['publisher'], book['category'], book['cover_url'], book['description']))
        book_id = cursor.lastrowid

        # æ’å…¥ä½œè€… + é—œè¯è¡¨
        for author_name in book['authors']:
            cursor.execute("SELECT author_id FROM author WHERE name=%s", (author_name,))
            author_result = cursor.fetchone()
            if author_result:
                author_id = author_result[0]
            else:
                cursor.execute("INSERT INTO author (name) VALUES (%s)", (author_name,))
                author_id = cursor.lastrowid
            cursor.execute("INSERT INTO book_author (book_id, author_id) VALUES (%s, %s)", (book_id, author_id))

        conn.commit()
        print(f"âœ… å·²åŒ¯å…¥ã€Š{book['title']}ã€‹è‡³è³‡æ–™åº«ã€‚")

if __name__ == '__main__':
    # è³‡æ–™åº«é€£ç·šè¨­å®š
    db_config = {
        'host': '127.0.0.1',
        'port': 3306,
        'user': 'admin',
        'password': 'Admin1234!',
        'database': 'book_system',
        'charset': 'utf8mb4'
    }

    print("ğŸ“¥ è«‹è²¼ä¸Šå¤šå€‹åšå®¢ä¾†ç¶²å€ï¼ˆæ¯è¡Œä¸€å€‹ï¼‰ï¼Œè¼¸å…¥ç©ºè¡ŒçµæŸï¼š")
    urls = []
    while True:
        line = input()
        if line.strip() == '':
            break
        urls.append(line.strip())

    # å»ºç«‹è³‡æ–™åº«é€£ç·š
    conn = pymysql.connect(autocommit=False, **db_config)

    for idx, url in enumerate(urls, start=1):
        print(f"\nğŸ” [{idx}] æŠ“å–ï¼š{url}")
        try:
            book = fetch_book_info(url)
            if book['title']:
                print("ğŸ“˜ æŠ“å–æˆåŠŸï¼š")
                print(json.dumps(book, ensure_ascii=False, indent=2))
                save_book_to_db(conn, book)
            else:
                print("âš ï¸ æŠ“ä¸åˆ°æ›¸åï¼Œè·³éã€‚")
        except Exception as e:
            print(f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

    conn.close()
    print("\nâœ… å…¨éƒ¨è™•ç†å®Œæˆï¼")
